{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2II-hbKAKFuL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b743a16-3bff-4e0e-8972-5df27f8cf825"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.6/463.6 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gradio 5.50.0 requires pydantic<=2.12.3,>=2.0, but you have pydantic 2.12.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip -q install -U langgraph openai pydantic"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Global Configs"
      ],
      "metadata": {
        "id": "Mpvk9ApTKFuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "WOLFRAM_APP_ID = userdata.get('WOLFRAM_APP_ID')\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "MODEL = \"gpt-5.2\"\n",
        "SERVICE_TIER = \"flex\"\n",
        "LANGUAGE = 'Ukrainian'"
      ],
      "metadata": {
        "id": "24KHLODqKFuM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shared Components"
      ],
      "metadata": {
        "id": "kmick4xMKFuM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompts"
      ],
      "metadata": {
        "id": "exbKLRNplRLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRANSLATION_SYSTEM = \"\"\"You are a professional mathematical translator. Translate the given mathematical content into {language}.\n",
        "\n",
        "Rules:\n",
        "- Preserve ALL LaTeX notation exactly as-is (do not translate math expressions)\n",
        "- Translate only the natural language portions\n",
        "- Maintain the same markdown formatting\n",
        "- Keep mathematical terms precise and use standard terminology in the target language\n",
        "- Do not add or remove any content\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "MMFaCNy3lSmi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRANSLATION_USER = \"\"\"Translate the following mathematical content into {language}:\n",
        "\n",
        "{content}\"\"\""
      ],
      "metadata": {
        "id": "BycMgapylVPP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WOLFRAM_TO_LATEX_SYSTEM = \"\"\"You are a mathematical notation converter. Convert Wolfram|Alpha plaintext output to clean LaTeX.\n",
        "\n",
        "Rules:\n",
        "- Output ONLY the LaTeX expression, nothing else\n",
        "- Use proper LaTeX commands: \\\\frac{}{}, \\\\sqrt{}, \\\\int, \\\\sum, etc.\n",
        "- Use \\\\ln for natural log (not \\\\log)\n",
        "- Replace \"constant\" with \"+ C\" for indefinite integrals\n",
        "- Handle multiple solutions by separating with \\\\\\\\ (newline in LaTeX)\n",
        "- Do not include equation numbers or labels\n",
        "- Do not wrap in $ or $$ delimiters\n",
        "\"\"\"\n",
        "\n",
        "WOLFRAM_TO_LATEX_USER = \"\"\"Convert this Wolfram|Alpha result to LaTeX:\n",
        "\n",
        "{plaintext}\"\"\""
      ],
      "metadata": {
        "id": "AEHa511ATJJ7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models"
      ],
      "metadata": {
        "id": "xL3sPKQjKFuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Literal, TypedDict"
      ],
      "metadata": {
        "id": "XzMJmxtPKFuN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Problem(BaseModel):\n",
        "    \"\"\"A generated math problem.\"\"\"\n",
        "    statement_latex: str = Field(description=\"Full problem statement (natural language + LaTeX allowed).\")\n",
        "    domain: Literal[\"calculus\", \"linear_algebra\"]\n",
        "    topic: str\n",
        "    difficulty: Literal[\"easy\", \"medium\", \"hard\"]\n",
        "    tags: List[str] = Field(default_factory=list)"
      ],
      "metadata": {
        "id": "xDdXIrieKFuN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Equation(BaseModel):\n",
        "    \"\"\"A single practice equation, compatible with Problem for solving.\"\"\"\n",
        "    statement_latex: str = Field(description=\"Instruction + equation, e.g., 'Compute: $\\\\int x^2 \\\\, dx$'\")\n",
        "    wolfram_query: str = Field(description=\"Wolfram|Alpha query for this equation, e.g., 'integrate x^2 dx'\")\n",
        "    tags: List[str] = Field(default_factory=list)"
      ],
      "metadata": {
        "id": "K_bUlfyywVpz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilities"
      ],
      "metadata": {
        "id": "9aYoOotsKFuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import re\n",
        "import time\n",
        "import requests\n",
        "from pydantic import ValidationError\n",
        "from langgraph.graph import START, END, StateGraph\n",
        "from openai import OpenAI\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "LsuTFdeYKFuN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wolfram_to_latex(plaintext: str, token_usage: dict = None, usage_log: list = None) -> dict:\n",
        "    \"\"\"\n",
        "    Convert Wolfram|Alpha plaintext to LaTeX using LLM.\n",
        "\n",
        "    Returns dict with 'latex', 'token_usage', 'usage_log'\n",
        "    \"\"\"\n",
        "    if not plaintext:\n",
        "        return {\n",
        "            \"latex\": \"\",\n",
        "            \"token_usage\": token_usage or {\"input\": 0, \"output\": 0, \"total\": 0},\n",
        "            \"usage_log\": usage_log or [],\n",
        "        }\n",
        "\n",
        "    token_usage = dict(token_usage or {\"input\": 0, \"output\": 0, \"total\": 0})\n",
        "    usage_log = list(usage_log or [])\n",
        "\n",
        "    try:\n",
        "        resp = client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            service_tier=SERVICE_TIER,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": WOLFRAM_TO_LATEX_SYSTEM},\n",
        "                {\"role\": \"user\", \"content\": WOLFRAM_TO_LATEX_USER.format(plaintext=plaintext)},\n",
        "            ],\n",
        "            temperature=0.0,\n",
        "            max_completion_tokens=500,\n",
        "        )\n",
        "\n",
        "        latex_result = resp.choices[0].message.content.strip()\n",
        "\n",
        "        # Clean up any accidental delimiters\n",
        "        latex_result = latex_result.strip('$').strip()\n",
        "\n",
        "        usage = getattr(resp, \"usage\", None)\n",
        "        if usage is not None:\n",
        "            token_usage[\"input\"] += int(getattr(usage, \"prompt_tokens\", 0))\n",
        "            token_usage[\"output\"] += int(getattr(usage, \"completion_tokens\", 0))\n",
        "            token_usage[\"total\"] += int(getattr(usage, \"total_tokens\", 0))\n",
        "            usage_log.append({\n",
        "                \"stage\": \"wolfram_to_latex\",\n",
        "                \"input_tokens\": int(getattr(usage, \"prompt_tokens\", 0)),\n",
        "                \"output_tokens\": int(getattr(usage, \"completion_tokens\", 0)),\n",
        "                \"total_tokens\": int(getattr(usage, \"total_tokens\", 0)),\n",
        "            })\n",
        "\n",
        "        return {\n",
        "            \"latex\": latex_result,\n",
        "            \"token_usage\": token_usage,\n",
        "            \"usage_log\": usage_log,\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[wolfram_to_latex] Error: {e}\")\n",
        "        return {\n",
        "            \"latex\": \"\",\n",
        "            \"token_usage\": token_usage,\n",
        "            \"usage_log\": usage_log,\n",
        "        }"
      ],
      "metadata": {
        "id": "-wQHM-IUTO3b"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def robust_parse(\n",
        "    client,\n",
        "    instructions: str,\n",
        "    prompt: str,\n",
        "    response_format,\n",
        "    temperature: float = 0.5,\n",
        "    max_completion_tokens: int = 1500,\n",
        "    max_retries: int = 3,\n",
        "):\n",
        "    \"\"\"\n",
        "    Wrapper for structured output parsing with retry logic.\n",
        "    Handles truncation, validation and API errors.\n",
        "    \"\"\"\n",
        "    last_error = None\n",
        "\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            adjusted_tokens = max_completion_tokens + (attempt * 500)\n",
        "\n",
        "            resp = client.responses.parse(\n",
        "                model=MODEL,\n",
        "                service_tier=SERVICE_TIER,\n",
        "                instructions=instructions,\n",
        "                input=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                text_format=response_format,\n",
        "                temperature=temperature,\n",
        "                max_output_tokens=adjusted_tokens,\n",
        "            )\n",
        "\n",
        "            return {\n",
        "                \"parsed\": resp.output_parsed,\n",
        "                \"usage\": getattr(resp, \"usage\", None),\n",
        "                \"attempts\": attempt + 1,\n",
        "            }\n",
        "\n",
        "        except ValidationError as e:\n",
        "            last_error = e\n",
        "            print(f\"[Attempt {attempt + 1}/{max_retries}] Validation error: {str(e)[:100]}...\")\n",
        "            time.sleep(0.5)\n",
        "            temperature = max(0.2, temperature - 0.1)\n",
        "\n",
        "        except Exception as e:\n",
        "            last_error = e\n",
        "            print(f\"[Attempt {attempt + 1}/{max_retries}] Unexpected error: {str(e)[:100]}...\")\n",
        "            time.sleep(0.5)\n",
        "\n",
        "    raise RuntimeError(f\"Failed after {max_retries} attempts. Last error: {last_error}\")"
      ],
      "metadata": {
        "id": "-Ks6SKE3KFuN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_text(content: str, target_language: str, token_usage: dict = None, usage_log: list = None) -> dict:\n",
        "    \"\"\"\n",
        "    Translate mathematical content to the target language.\n",
        "    Preserves LaTeX notation and markdown formatting.\n",
        "\n",
        "    Returns dict with 'translated', 'token_usage', 'usage_log'\n",
        "    \"\"\"\n",
        "    if not target_language or target_language.lower() == \"english\":\n",
        "        return {\n",
        "            \"translated\": content,\n",
        "            \"token_usage\": token_usage or {\"input\": 0, \"output\": 0, \"total\": 0},\n",
        "            \"usage_log\": usage_log or [],\n",
        "        }\n",
        "\n",
        "    token_usage = dict(token_usage or {\"input\": 0, \"output\": 0, \"total\": 0})\n",
        "    usage_log = list(usage_log or [])\n",
        "\n",
        "    try:\n",
        "        resp = client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            service_tier=SERVICE_TIER,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": TRANSLATION_SYSTEM.format(language=target_language)},\n",
        "                {\"role\": \"user\", \"content\": TRANSLATION_USER.format(language=target_language, content=content)},\n",
        "            ],\n",
        "            temperature=0.3,\n",
        "            max_completion_tokens=2000,\n",
        "        )\n",
        "\n",
        "        translated = resp.choices[0].message.content\n",
        "\n",
        "        usage = getattr(resp, \"usage\", None)\n",
        "        if usage is not None:\n",
        "            token_usage[\"input\"] += int(getattr(usage, \"prompt_tokens\", 0))\n",
        "            token_usage[\"output\"] += int(getattr(usage, \"completion_tokens\", 0))\n",
        "            token_usage[\"total\"] += int(getattr(usage, \"total_tokens\", 0))\n",
        "            usage_log.append({\n",
        "                \"stage\": f\"translate_to_{target_language}\",\n",
        "                \"input_tokens\": int(getattr(usage, \"prompt_tokens\", 0)),\n",
        "                \"output_tokens\": int(getattr(usage, \"completion_tokens\", 0)),\n",
        "                \"total_tokens\": int(getattr(usage, \"total_tokens\", 0)),\n",
        "            })\n",
        "\n",
        "        return {\n",
        "            \"translated\": translated,\n",
        "            \"token_usage\": token_usage,\n",
        "            \"usage_log\": usage_log,\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[translate_text] Error: {e}\")\n",
        "        return {\n",
        "            \"translated\": content,  # Fallback to original\n",
        "            \"token_usage\": token_usage,\n",
        "            \"usage_log\": usage_log,\n",
        "        }"
      ],
      "metadata": {
        "id": "w351npVUlmWQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def render_latex_for_markdown(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Convert LaTeX delimiters to markdown-compatible format.\n",
        "    Converts: \\\\[...\\\\] → $$...$$ and \\\\(...\\\\) → $...$\n",
        "    \"\"\"\n",
        "    text = re.sub(r\"\\\\\\[\\s*\", \"$$\\n\", text)\n",
        "    text = re.sub(r\"\\s*\\\\\\]\", \"\\n$$\", text)\n",
        "    text = re.sub(r\"\\\\\\(\", \"$\", text)\n",
        "    text = re.sub(r\"\\\\\\)\", \"$\", text)\n",
        "    return text\n",
        "\n",
        "\n",
        "def print_problem(s: str) -> None:\n",
        "    display(Markdown(render_latex_for_markdown(s)))\n",
        "\n",
        "\n",
        "def print_solution(s: str) -> None:\n",
        "    display(Markdown(render_latex_for_markdown(s)))"
      ],
      "metadata": {
        "id": "nVbUeqgSKFuN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_token_summary(token_usage: dict) -> str:\n",
        "    \"\"\"Format token usage as consistent string.\"\"\"\n",
        "    return (\n",
        "        f\"Input: {token_usage.get('input', 0)} | \"\n",
        "        f\"Output: {token_usage.get('output', 0)} | \"\n",
        "        f\"Total: {token_usage.get('total', 0)}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "tWErDpul58FV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Equation Generator Agent"
      ],
      "metadata": {
        "id": "tNZSV3xDvrVL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models"
      ],
      "metadata": {
        "id": "KBoG_EJivwEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EquationSkeletonItem(BaseModel):\n",
        "    structure: str\n",
        "    technique: str\n",
        "    complexity: str"
      ],
      "metadata": {
        "id": "MAfCKdK2v-QK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EquationSkeletonList(BaseModel):\n",
        "    items: List[EquationSkeletonItem]"
      ],
      "metadata": {
        "id": "4iJjtXvgwZLV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EquationGeneratorState(TypedDict, total=False):\n",
        "    # Input\n",
        "    domain: str\n",
        "    topic: str\n",
        "    difficulty: str\n",
        "    target_language: str\n",
        "\n",
        "    # Skeleton stage\n",
        "    equation_skeletons: list[dict]\n",
        "    selected_skeleton: dict\n",
        "\n",
        "    # Generation\n",
        "    attempts: int\n",
        "    errors: list[str]\n",
        "\n",
        "    # Output\n",
        "    equation: Equation\n",
        "    equation_markdown: str\n",
        "    equation_markdown_translated: str\n",
        "\n",
        "    # Tracking\n",
        "    token_usage: dict\n",
        "    usage_log: list[dict]"
      ],
      "metadata": {
        "id": "hD7WKuGOwblu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompts"
      ],
      "metadata": {
        "id": "CmI8WUPOv5sE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EQUATION_SYSTEM_PROMPT = \"\"\"You are a math drill generator specializing in creating practice equations.\n",
        "Generate ONE concise, one-liner equation for students to practice raw calculation skills.\n",
        "\n",
        "Rules:\n",
        "- The equation must be self-contained and solvable\n",
        "- Combine instruction and equation into a single statement\n",
        "- Format: \"Instruction: $latex$\" (e.g., \"Compute: $\\\\int x^2 \\\\, dx$\")\n",
        "- Instruction should be ONE word or short phrase: \"Compute\", \"Solve\", \"Evaluate\", \"Find\", \"Simplify\", \"Prove that\", etc.\n",
        "- Use $...$ delimiters for LaTeX\n",
        "- Do NOT include solutions, answers, or hints\n",
        "- Provide a Wolfram|Alpha query that will solve this equation (plain text, not LaTeX)\n",
        "\"\"\"\n",
        "\n",
        "EQUATION_GENERATION_USER = \"\"\"Generate ONE practice equation based on this concept:\n",
        "\n",
        "Domain: {domain}\n",
        "Topic: \"{topic}\"\n",
        "Difficulty: {difficulty}\n",
        "\n",
        "**Equation concept to develop:**\n",
        "- Structure: {structure}\n",
        "- Technique: {technique}\n",
        "- Complexity note: {complexity}\n",
        "\n",
        "Requirements:\n",
        "- Single one-liner in format: \"Instruction: $latex$\"\n",
        "- Example: \"Compute: $\\\\int \\\\frac{{2x}}{{1+x^2}} \\\\, dx$\"\n",
        "- Instruction should be minimal: \"Compute\", \"Solve\", \"Evaluate\", \"Simplify\", \"Find\", or \"Prove that\"\n",
        "- Include a wolfram_query field with the plain-text Wolfram|Alpha query (e.g., \"integrate 2x/(1+x^2) dx\")\n",
        "\n",
        "Return a JSON object with statement_latex, wolfram_query, and tags.\"\"\"\n",
        "\n",
        "EQUATION_SKELETON_SYSTEM = \"\"\"You are a math curriculum designer. Generate DIVERSE equation concepts for practice drills.\n",
        "Focus on varying the mathematical structures, techniques required, and complexity.\"\"\"\n",
        "\n",
        "EQUATION_SKELETON_USER = \"\"\"For the topic \"{topic}\" in {domain} at {difficulty} level, propose {n} DIVERSE equation/expression types.\n",
        "\n",
        "Examples of variation:\n",
        "- Different function types (polynomial, rational, trigonometric, exponential, logarithmic)\n",
        "- Different techniques (substitution, parts, partial fractions, trig identities)\n",
        "- Different structures (definite vs indefinite, single vs nested, with parameters)\n",
        "\n",
        "Return a JSON array of {n} objects with:\n",
        "- structure: brief description of the equation structure (e.g., \"rational function with quadratic denominator\")\n",
        "- technique: primary technique needed (e.g., \"partial fractions\")\n",
        "- complexity: what makes it interesting at this difficulty level\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "sByB7001v7GS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nodes"
      ],
      "metadata": {
        "id": "8sVEXx4jwhxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_equation_skeletons(state: EquationGeneratorState) -> dict:\n",
        "    \"\"\"Generate diverse equation structure concepts, then randomly select one.\"\"\"\n",
        "    topic = state.get(\"topic\", \"\").strip()\n",
        "    domain = state.get(\"domain\", \"calculus\")\n",
        "    difficulty = state.get(\"difficulty\", \"medium\")\n",
        "\n",
        "    prompt = EQUATION_SKELETON_USER.format(\n",
        "        topic=topic, domain=domain, difficulty=difficulty, n=5\n",
        "    )\n",
        "\n",
        "    result = robust_parse(\n",
        "        client=client,\n",
        "        instructions=EQUATION_SKELETON_SYSTEM,\n",
        "        prompt=prompt,\n",
        "        response_format=EquationSkeletonList,\n",
        "        temperature=1.0,\n",
        "        max_completion_tokens=600,\n",
        "        max_retries=3,\n",
        "    )\n",
        "\n",
        "    skeletons = [s.model_dump() for s in result[\"parsed\"].items]\n",
        "    selected = random.choice(skeletons)\n",
        "\n",
        "    usage = result[\"usage\"]\n",
        "    token_usage = dict(state.get(\"token_usage\", {\"input\": 0, \"output\": 0, \"total\": 0}))\n",
        "    usage_log = list(state.get(\"usage_log\", []))\n",
        "\n",
        "    if usage is not None:\n",
        "        token_usage[\"input\"] += int(getattr(usage, \"input_tokens\", 0))\n",
        "        token_usage[\"output\"] += int(getattr(usage, \"output_tokens\", 0))\n",
        "        token_usage[\"total\"] += int(getattr(usage, \"total_tokens\", 0))\n",
        "        usage_log.append({\n",
        "            \"stage\": \"equation_skeletons\",\n",
        "            \"attempts\": result[\"attempts\"],\n",
        "            \"input_tokens\": int(getattr(usage, \"input_tokens\", 0)),\n",
        "            \"output_tokens\": int(getattr(usage, \"output_tokens\", 0)),\n",
        "            \"total_tokens\": int(getattr(usage, \"total_tokens\", 0)),\n",
        "        })\n",
        "\n",
        "    return {\n",
        "        \"equation_skeletons\": skeletons,\n",
        "        \"selected_skeleton\": selected,\n",
        "        \"token_usage\": token_usage,\n",
        "        \"usage_log\": usage_log,\n",
        "    }"
      ],
      "metadata": {
        "id": "MpdFTHMSwjDX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_equation(state: EquationGeneratorState) -> dict:\n",
        "    \"\"\"Generate a single equation based on selected skeleton.\"\"\"\n",
        "    topic = state.get(\"topic\", \"\").strip()\n",
        "    domain = state.get(\"domain\", \"calculus\")\n",
        "    difficulty = state.get(\"difficulty\", \"medium\")\n",
        "    skeleton = state[\"selected_skeleton\"]\n",
        "\n",
        "    prompt = EQUATION_GENERATION_USER.format(\n",
        "        domain=domain,\n",
        "        topic=topic,\n",
        "        difficulty=difficulty,\n",
        "        structure=skeleton[\"structure\"],\n",
        "        technique=skeleton[\"technique\"],\n",
        "        complexity=skeleton[\"complexity\"],\n",
        "    )\n",
        "\n",
        "    result = robust_parse(\n",
        "        client=client,\n",
        "        instructions=EQUATION_SYSTEM_PROMPT,\n",
        "        prompt=prompt,\n",
        "        response_format=Equation,\n",
        "        temperature=0.8,\n",
        "        max_completion_tokens=300,\n",
        "        max_retries=3,\n",
        "    )\n",
        "\n",
        "    equation = result[\"parsed\"]\n",
        "\n",
        "    usage = result[\"usage\"]\n",
        "    token_usage = dict(state.get(\"token_usage\", {\"input\": 0, \"output\": 0, \"total\": 0}))\n",
        "    usage_log = list(state.get(\"usage_log\", []))\n",
        "\n",
        "    if usage is not None:\n",
        "        token_usage[\"input\"] += int(getattr(usage, \"input_tokens\", 0))\n",
        "        token_usage[\"output\"] += int(getattr(usage, \"output_tokens\", 0))\n",
        "        token_usage[\"total\"] += int(getattr(usage, \"total_tokens\", 0))\n",
        "        usage_log.append({\n",
        "            \"stage\": \"generate_equation\",\n",
        "            \"attempts\": state.get(\"attempts\", 0) + 1,\n",
        "            \"input_tokens\": int(getattr(usage, \"input_tokens\", 0)),\n",
        "            \"output_tokens\": int(getattr(usage, \"output_tokens\", 0)),\n",
        "            \"total_tokens\": int(getattr(usage, \"total_tokens\", 0)),\n",
        "        })\n",
        "\n",
        "    return {\n",
        "        \"equation\": equation,\n",
        "        \"token_usage\": token_usage,\n",
        "        \"usage_log\": usage_log,\n",
        "    }"
      ],
      "metadata": {
        "id": "DeMT-37pwmQF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_equation(state: EquationGeneratorState) -> dict:\n",
        "    \"\"\"Validate the generated equation.\"\"\"\n",
        "    eq = state.get(\"equation\")\n",
        "    errors = []\n",
        "\n",
        "    if not eq:\n",
        "        errors.append(\"No equation generated.\")\n",
        "        return {\"errors\": errors, \"attempts\": state.get(\"attempts\", 0) + 1}\n",
        "\n",
        "    if not eq.statement_latex:\n",
        "        errors.append(\"Missing statement_latex.\")\n",
        "    elif \"$\" not in eq.statement_latex:\n",
        "        errors.append(\"Statement should contain LaTeX with $...$ delimiters.\")\n",
        "    elif \":\" not in eq.statement_latex:\n",
        "        errors.append(\"Statement should have format 'Instruction: $latex$'.\")\n",
        "\n",
        "    solution_patterns = [r\"=\\s*-?\\d+\\.?\\d*\\s*\\$\", r\"\\banswer\\b\", r\"\\bsolution\\b\"]\n",
        "    for pattern in solution_patterns:\n",
        "        if re.search(pattern, eq.statement_latex, re.IGNORECASE):\n",
        "            errors.append(\"Equation may contain an answer/solution.\")\n",
        "            break\n",
        "\n",
        "    return {\n",
        "        \"errors\": errors,\n",
        "        \"attempts\": state.get(\"attempts\", 0) + 1,\n",
        "    }"
      ],
      "metadata": {
        "id": "xESfe0-Twpq2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def finalize_equation(state: EquationGeneratorState) -> dict:\n",
        "    \"\"\"Render equation as markdown and translate if needed.\"\"\"\n",
        "    eq = state[\"equation\"]\n",
        "    target_language = state.get(\"target_language\", \"\")\n",
        "\n",
        "    # statement_latex is already the complete output\n",
        "    equation_md = eq.statement_latex\n",
        "\n",
        "    # Translate if needed\n",
        "    result = translate_text(\n",
        "        content=equation_md,\n",
        "        target_language=target_language,\n",
        "        token_usage=state.get(\"token_usage\"),\n",
        "        usage_log=state.get(\"usage_log\"),\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"equation_markdown\": equation_md,\n",
        "        \"equation_markdown_translated\": result[\"translated\"],\n",
        "        \"token_usage\": result[\"token_usage\"],\n",
        "        \"usage_log\": result[\"usage_log\"],\n",
        "    }"
      ],
      "metadata": {
        "id": "6tO8EIYVwrsf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Edges"
      ],
      "metadata": {
        "id": "DwflCBmjwwBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def route_after_equation_validate(state: EquationGeneratorState) -> str:\n",
        "    \"\"\"Route based on validation. Retry if errors and under limit.\"\"\"\n",
        "    if state.get(\"errors\") and state.get(\"attempts\", 0) < 3:\n",
        "        return \"retry\"\n",
        "    return \"done\""
      ],
      "metadata": {
        "id": "Y5j4cli-ww-u"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compilation"
      ],
      "metadata": {
        "id": "8eXq5DZUwxs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equation_graph = StateGraph(EquationGeneratorState)\n",
        "\n",
        "equation_graph.add_node(\"generate_equation_skeletons\", generate_equation_skeletons)\n",
        "equation_graph.add_node(\"generate_equation\", generate_equation)\n",
        "equation_graph.add_node(\"validate_equation\", validate_equation)\n",
        "equation_graph.add_node(\"finalize_equation\", finalize_equation)\n",
        "\n",
        "equation_graph.add_edge(START, \"generate_equation_skeletons\")\n",
        "equation_graph.add_edge(\"generate_equation_skeletons\", \"generate_equation\")\n",
        "equation_graph.add_edge(\"generate_equation\", \"validate_equation\")\n",
        "\n",
        "equation_graph.add_conditional_edges(\n",
        "    \"validate_equation\",\n",
        "    route_after_equation_validate,\n",
        "    {\"retry\": \"generate_equation\", \"done\": \"finalize_equation\"},\n",
        ")\n",
        "\n",
        "equation_graph.add_edge(\"finalize_equation\", END)\n",
        "\n",
        "equation_generator = equation_graph.compile()"
      ],
      "metadata": {
        "id": "71cDClrjw0ag"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Problem Generator Agent"
      ],
      "metadata": {
        "id": "budaGcWUKFuN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompts"
      ],
      "metadata": {
        "id": "y3LDBaGiKFuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GENERATOR_SYSTEM_PROMPT = \"\"\"You are Math Tutor: a college-level math PROBLEM GENERATOR.\n",
        "Generate exactly ONE practice problem ONLY.\n",
        "\n",
        "Hard constraints:\n",
        "- Do NOT include any solution steps, hints that reveal the solution, or final answers.\n",
        "- Output MUST match the JSON schema exactly.\n",
        "- statement_latex may include natural language + LaTeX math blocks.\n",
        "- Use $...$ for inline math and $$...$$ for display math.\n",
        "\"\"\"\n",
        "\n",
        "SKELETON_SYSTEM = \"\"\"You are a creative math curriculum designer. Your job is to propose DIVERSE problem concepts—not full problems, just ideas that vary in structure, context, and required techniques.\"\"\"\n",
        "\n",
        "SKELETON_USER_TEMPLATE = \"\"\"For the topic \"{topic}\" in {domain} at {difficulty} level, propose {n} VERY DIFFERENT problem concepts.\n",
        "\n",
        "Vary across these dimensions:\n",
        "- Problem type (computational, proof, conceptual, construction, counterexample, application)\n",
        "- Mathematical objects (functions, sequences, matrices, geometric shapes, etc.)\n",
        "- Context (pure math, physics, economics, geometry, probability)\n",
        "- Required technique or insight\n",
        "\n",
        "Return a JSON array of {n} objects with:\n",
        "- concept: one-sentence description of the problem idea\n",
        "- problem_type: one of [computational, proof, conceptual, construction, counterexample, application, multi-part]\n",
        "- key_twist: what makes this problem interesting or non-standard\n",
        "\"\"\"\n",
        "\n",
        "GENERATION_USER_TEMPLATE = \"\"\"Generate 1 practice problem based on this concept:\n",
        "\n",
        "Domain: {domain}\n",
        "Topic: \"{topic}\"\n",
        "Difficulty: {difficulty}\n",
        "\n",
        "**Problem concept to develop:**\n",
        "{concept}\n",
        "\n",
        "**Problem type:** {problem_type}\n",
        "**Key twist to incorporate:** {key_twist}\n",
        "\n",
        "Expand this concept into a complete, well-posed problem. Return ONLY the JSON object.\"\"\""
      ],
      "metadata": {
        "id": "Tjd2o4GgKFuN"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## State"
      ],
      "metadata": {
        "id": "ZAS9G2V9KFuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GeneratorState(TypedDict, total=False):\n",
        "    topic: str\n",
        "    domain: str\n",
        "    difficulty: str\n",
        "    target_language: str\n",
        "\n",
        "    skeletons: list[dict]\n",
        "    selected_skeleton: dict\n",
        "\n",
        "    prompt: str\n",
        "    attempts: int\n",
        "    errors: list[str]\n",
        "\n",
        "    problem: Problem\n",
        "    problem_markdown: str\n",
        "    problem_markdown_translated: str\n",
        "\n",
        "    token_usage: dict\n",
        "    usage_log: list[dict]"
      ],
      "metadata": {
        "id": "QsXEoS3CKFuO"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models"
      ],
      "metadata": {
        "id": "-s6EtMgqKFuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SkeletonItem(BaseModel):\n",
        "    concept: str\n",
        "    problem_type: str\n",
        "    key_twist: str\n",
        "\n",
        "\n",
        "class SkeletonList(BaseModel):\n",
        "    items: List[SkeletonItem]"
      ],
      "metadata": {
        "id": "TqMGZNTOKFuO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nodes"
      ],
      "metadata": {
        "id": "ZTIWUpCAKFuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_skeletons(state: GeneratorState) -> dict:\n",
        "    \"\"\"Generates a diverse set of problem concepts (skeletons). Randomly selects one.\"\"\"\n",
        "    topic = state[\"topic\"].strip()\n",
        "    domain = state.get(\"domain\", \"calculus\")\n",
        "    difficulty = state.get(\"difficulty\", \"medium\")\n",
        "\n",
        "    prompt = SKELETON_USER_TEMPLATE.format(\n",
        "        topic=topic, domain=domain, difficulty=difficulty, n=5,\n",
        "    )\n",
        "\n",
        "    result = robust_parse(\n",
        "        client=client,\n",
        "        instructions=SKELETON_SYSTEM,\n",
        "        prompt=prompt,\n",
        "        response_format=SkeletonList,\n",
        "        temperature=1.1,\n",
        "        max_completion_tokens=800,\n",
        "        max_retries=3,\n",
        "    )\n",
        "\n",
        "    skeletons = [s.model_dump() for s in result[\"parsed\"].items]\n",
        "    selected = random.choice(skeletons)\n",
        "\n",
        "    usage = result[\"usage\"]\n",
        "    token_usage = dict(state.get(\"token_usage\", {\"input\": 0, \"output\": 0, \"total\": 0}))\n",
        "    usage_log = list(state.get(\"usage_log\", []))\n",
        "\n",
        "    if usage is not None:\n",
        "        token_usage[\"input\"] += int(getattr(usage, \"input_tokens\", 0))\n",
        "        token_usage[\"output\"] += int(getattr(usage, \"output_tokens\", 0))\n",
        "        token_usage[\"total\"] += int(getattr(usage, \"total_tokens\", 0))\n",
        "        usage_log.append({\n",
        "            \"stage\": \"skeleton\",\n",
        "            \"attempts\": result[\"attempts\"],\n",
        "            \"input_tokens\": int(getattr(usage, \"input_tokens\", 0)),\n",
        "            \"output_tokens\": int(getattr(usage, \"output_tokens\", 0)),\n",
        "            \"total_tokens\": int(getattr(usage, \"total_tokens\", 0)),\n",
        "        })\n",
        "\n",
        "    return {\n",
        "        \"skeletons\": skeletons,\n",
        "        \"selected_skeleton\": selected,\n",
        "        \"token_usage\": token_usage,\n",
        "        \"usage_log\": usage_log,\n",
        "    }"
      ],
      "metadata": {
        "id": "zQF_4VPNKFuO"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_prompt(state: GeneratorState) -> dict:\n",
        "    \"\"\"Builds the problem generation prompt using the selected skeleton.\"\"\"\n",
        "    topic = state[\"topic\"].strip()\n",
        "    domain = state.get(\"domain\", \"calculus\")\n",
        "    difficulty = state.get(\"difficulty\", \"medium\")\n",
        "    skeleton = state[\"selected_skeleton\"]\n",
        "\n",
        "    prompt = GENERATION_USER_TEMPLATE.format(\n",
        "        domain=domain,\n",
        "        topic=topic,\n",
        "        difficulty=difficulty,\n",
        "        concept=skeleton[\"concept\"],\n",
        "        problem_type=skeleton[\"problem_type\"],\n",
        "        key_twist=skeleton[\"key_twist\"],\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"topic\": topic,\n",
        "        \"domain\": domain,\n",
        "        \"difficulty\": difficulty,\n",
        "        \"prompt\": prompt,\n",
        "        \"attempts\": state.get(\"attempts\", 0),\n",
        "        \"errors\": [],\n",
        "        \"token_usage\": state.get(\"token_usage\", {\"input\": 0, \"output\": 0, \"total\": 0}),\n",
        "        \"usage_log\": state.get(\"usage_log\", []),\n",
        "    }"
      ],
      "metadata": {
        "id": "QrzZ1mwxKFuO"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_problem(state: GeneratorState) -> dict:\n",
        "    \"\"\"Takes a skeleton-adjusted prompt and generates a problem.\"\"\"\n",
        "    result = robust_parse(\n",
        "        client=client,\n",
        "        instructions=GENERATOR_SYSTEM_PROMPT,\n",
        "        prompt=state[\"prompt\"],\n",
        "        response_format=Problem,\n",
        "        temperature=0.9,\n",
        "        max_completion_tokens=1500,\n",
        "        max_retries=3,\n",
        "    )\n",
        "\n",
        "    problem: Problem = result[\"parsed\"]\n",
        "\n",
        "    usage = result[\"usage\"]\n",
        "    token_usage = dict(state.get(\"token_usage\", {\"input\": 0, \"output\": 0, \"total\": 0}))\n",
        "    usage_log = list(state.get(\"usage_log\", []))\n",
        "\n",
        "    if usage is not None:\n",
        "        token_usage[\"input\"] += int(getattr(usage, \"input_tokens\", 0))\n",
        "        token_usage[\"output\"] += int(getattr(usage, \"output_tokens\", 0))\n",
        "        token_usage[\"total\"] += int(getattr(usage, \"total_tokens\", 0))\n",
        "        usage_log.append({\n",
        "            \"attempt\": state.get(\"attempts\", 0) + 1,\n",
        "            \"parse_attempts\": result[\"attempts\"],\n",
        "            \"input_tokens\": int(getattr(usage, \"input_tokens\", 0)),\n",
        "            \"output_tokens\": int(getattr(usage, \"output_tokens\", 0)),\n",
        "            \"total_tokens\": int(getattr(usage, \"total_tokens\", 0)),\n",
        "        })\n",
        "\n",
        "    return {\"problem\": problem, \"token_usage\": token_usage, \"usage_log\": usage_log}"
      ],
      "metadata": {
        "id": "MASzz7JmKFuO"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_problem(state: GeneratorState) -> dict:\n",
        "    \"\"\"Rule-based validation of the generated problem.\"\"\"\n",
        "    p: Problem = state[\"problem\"]\n",
        "    errors = []\n",
        "\n",
        "    if state[\"topic\"].lower() not in p.topic.lower():\n",
        "        errors.append(f\"Returned topic '{p.topic}' drifted from requested '{state['topic']}'.\")\n",
        "\n",
        "    if p.domain != state[\"domain\"]:\n",
        "        errors.append(f\"Returned domain '{p.domain}' != requested '{state['domain']}'.\")\n",
        "    if p.difficulty != state[\"difficulty\"]:\n",
        "        errors.append(f\"Returned difficulty '{p.difficulty}' != requested '{state['difficulty']}'.\")\n",
        "\n",
        "    attempts = state.get(\"attempts\", 0) + 1\n",
        "    return {\"errors\": errors, \"attempts\": attempts}"
      ],
      "metadata": {
        "id": "5jXghRkUKFuO"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def finalize_problem(state: GeneratorState) -> dict:\n",
        "    \"\"\"Finalizes the problem: renders markdown and translates if needed.\"\"\"\n",
        "    problem_md = render_latex_for_markdown(state[\"problem\"].statement_latex)\n",
        "    target_language = state.get(\"target_language\", \"\")\n",
        "\n",
        "    # Translate if target language specified\n",
        "    result = translate_text(\n",
        "        content=problem_md,\n",
        "        target_language=target_language,\n",
        "        token_usage=state.get(\"token_usage\"),\n",
        "        usage_log=state.get(\"usage_log\"),\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"problem_markdown\": problem_md,\n",
        "        \"problem_markdown_translated\": result[\"translated\"],\n",
        "        \"token_usage\": result[\"token_usage\"],\n",
        "        \"usage_log\": result[\"usage_log\"],\n",
        "    }"
      ],
      "metadata": {
        "id": "hzVAhEP4lzbQ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Edges"
      ],
      "metadata": {
        "id": "rblQzSHIKFuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def route_after_problem_validate(state: GeneratorState) -> str:\n",
        "    \"\"\"Routes based on validation results. Retries generation if errors found.\"\"\"\n",
        "    if state.get(\"errors\") and state.get(\"attempts\", 0) < 3:\n",
        "        return \"retry\"\n",
        "    return \"done\""
      ],
      "metadata": {
        "id": "dI2aybGGKFuO"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compilation"
      ],
      "metadata": {
        "id": "CbMcy_xlKFuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator_graph = StateGraph(GeneratorState)\n",
        "\n",
        "generator_graph.add_node(\"generate_skeletons\", generate_skeletons)\n",
        "generator_graph.add_node(\"build_prompt\", build_prompt)\n",
        "generator_graph.add_node(\"generate_problem\", generate_problem)\n",
        "generator_graph.add_node(\"validate_problem\", validate_problem)\n",
        "generator_graph.add_node(\"finalize_problem\", finalize_problem)\n",
        "\n",
        "generator_graph.add_edge(START, \"generate_skeletons\")\n",
        "generator_graph.add_edge(\"generate_skeletons\", \"build_prompt\")\n",
        "generator_graph.add_edge(\"build_prompt\", \"generate_problem\")\n",
        "generator_graph.add_edge(\"generate_problem\", \"validate_problem\")\n",
        "\n",
        "generator_graph.add_conditional_edges(\n",
        "    \"validate_problem\",\n",
        "    route_after_problem_validate,\n",
        "    {\"retry\": \"generate_problem\", \"done\": \"finalize_problem\"},\n",
        ")\n",
        "\n",
        "generator_graph.add_edge(\"finalize_problem\", END)\n",
        "\n",
        "problem_generator = generator_graph.compile()"
      ],
      "metadata": {
        "id": "9c53bqU2KFuO"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Problem Solver Agent"
      ],
      "metadata": {
        "id": "sTF1J0CdKFuP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configs"
      ],
      "metadata": {
        "id": "1iQhoUOiKFuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WA_ENDPOINT = \"https://api.wolframalpha.com/v2/query\"\n",
        "MAX_PLAN_STEPS = 10\n",
        "MAX_STEP_SIZE_TOKENS = 200\n",
        "MAX_STEP_WOLFRAM_SIZE = 200"
      ],
      "metadata": {
        "id": "U47CyTPQKFuP"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompts"
      ],
      "metadata": {
        "id": "9XZoBLMUKFuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SOLUTION_PLANNER_SYSTEM = \"\"\"You are an expert math problem solver. Given a problem, create a step-by-step solution PLAN.\n",
        "\n",
        "For each step, specify:\n",
        "- step_number: integer\n",
        "- description: what this step accomplishes\n",
        "- step_type: one of [\"reasoning\", \"symbolic_compute\", \"verify\"]\n",
        "  - \"reasoning\": logical deduction, setting up equations, interpreting results\n",
        "  - \"symbolic_compute\": integration, differentiation, solving equations, simplification (use Wolfram)\n",
        "  - \"verify\": checking a result is correct\n",
        "- depends_on: list of step numbers this depends on (empty for first steps)\n",
        "- wolfram_query: if step_type is \"symbolic_compute\", provide the Wolfram|Alpha query (plain text, not LaTeX)\n",
        "\n",
        "Think carefully about what requires symbolic computation vs. pure reasoning.\"\"\"\n",
        "\n",
        "SOLUTION_PLANNER_USER = \"\"\"Create a solution plan for this problem:\n",
        "\n",
        "{problem_statement}\n",
        "\n",
        "Break it into atomic steps. For any symbolic computation (integrals, derivatives, solving equations, simplification), mark as \"symbolic_compute\" and provide the Wolfram query.\n",
        "\n",
        "IMPORTANT: Keep the plan concise. Maximum {max_steps} steps. Keep descriptions brief - under {max_tokens} tokens.\n",
        "\"\"\"\n",
        "\n",
        "STEP_EXECUTOR_SYSTEM = \"\"\"You are executing ONE step of a math solution. You have context from previous steps.\n",
        "\n",
        "Write clear, detailed mathematical reasoning for this step. Use LaTeX notation ($...$ for inline, $$...$$ for display).\n",
        "If Wolfram|Alpha results are provided, interpret and explain them.\n",
        "Be precise and show your work.\"\"\"\n",
        "\n",
        "STEP_EXECUTOR_USER = \"\"\"## Problem\n",
        "{problem_statement}\n",
        "\n",
        "## Current Step\n",
        "**Step {step_number}:** {step_description}\n",
        "\n",
        "## Previous Steps Completed\n",
        "{previous_steps}\n",
        "\n",
        "## Wolfram|Alpha Result (if applicable)\n",
        "{wolfram_result}\n",
        "\n",
        "Execute this step. Write clear mathematical reasoning with LaTeX notation.\"\"\"\n",
        "\n",
        "SOLUTION_COMPILER_SYSTEM = \"\"\"You are compiling individual solution steps into a polished, coherent final solution.\n",
        "- Maintain logical flow between steps\n",
        "- Use consistent LaTeX notation ($...$ for inline, $$...$$ for display)\n",
        "- Ensure the final answer is clearly stated\n",
        "- Format as clean Markdown with proper math blocks\"\"\"\n",
        "\n",
        "SOLUTION_COMPILER_USER = \"\"\"## Problem\n",
        "{problem_statement}\n",
        "\n",
        "## Executed Steps\n",
        "{all_steps}\n",
        "\n",
        "Compile these into a single, polished step-by-step solution. Ensure smooth transitions and a clear final answer.\"\"\""
      ],
      "metadata": {
        "id": "Jpz5D90MKFuP"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## State"
      ],
      "metadata": {
        "id": "WY1_T1yRKFuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SolverState(TypedDict, total=False):\n",
        "    # Input\n",
        "    problem: Problem | Equation\n",
        "    target_language: str\n",
        "    step_by_step: bool\n",
        "\n",
        "    # Planning\n",
        "    solution_plan: list[dict]\n",
        "    current_step_index: int\n",
        "    step_results: list[dict]\n",
        "\n",
        "    # Current solution attempt\n",
        "    solution: str\n",
        "    solution_errors: list[str]\n",
        "    solution_attempts: int\n",
        "\n",
        "    # Best solution tracking\n",
        "    best_solution: str\n",
        "    best_solution_errors: list[str]\n",
        "    best_solution_step_results: list[dict]\n",
        "\n",
        "    # WA tracking\n",
        "    wa_calls: int\n",
        "\n",
        "    # Token tracking\n",
        "    token_usage: dict\n",
        "    usage_log: list[dict]\n",
        "\n",
        "    # Output\n",
        "    solution_markdown: str\n",
        "    solution_markdown_translated: str\n",
        "    summary: str"
      ],
      "metadata": {
        "id": "48kWRUR4KFuP"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models"
      ],
      "metadata": {
        "id": "OEdJYWynKFuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SolutionStep(BaseModel):\n",
        "    step_number: int\n",
        "    description: str = Field(max_length=MAX_STEP_SIZE_TOKENS)\n",
        "    step_type: Literal[\"reasoning\", \"symbolic_compute\", \"verify\"]\n",
        "    depends_on: List[int] = Field(default_factory=list)\n",
        "    wolfram_query: str = Field(default=\"\", max_length=MAX_STEP_WOLFRAM_SIZE)\n",
        "\n",
        "\n",
        "class SolutionPlan(BaseModel):\n",
        "    steps: List[SolutionStep] = Field(max_length=MAX_PLAN_STEPS)"
      ],
      "metadata": {
        "id": "LcKGw2bKKFuP"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilities"
      ],
      "metadata": {
        "id": "MKgMN8ELKFuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def wolfram_solve(query: str, appid: str, timeout: int = 30) -> dict:\n",
        "    \"\"\"Query Wolfram|Alpha and extract computational results.\"\"\"\n",
        "    params = {\n",
        "        \"input\": query,\n",
        "        \"appid\": appid,\n",
        "        \"output\": \"json\",\n",
        "        \"format\": \"plaintext\",\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(WA_ENDPOINT, params=params, timeout=timeout)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "    except requests.RequestException as e:\n",
        "        return {\n",
        "            \"ok\": False,\n",
        "            \"result\": \"\",\n",
        "            \"pods\": [],\n",
        "            \"raw\": {},\n",
        "        }\n",
        "\n",
        "    query_result = data.get(\"queryresult\", {})\n",
        "\n",
        "    if not query_result.get(\"success\", False):\n",
        "        return {\n",
        "            \"ok\": False,\n",
        "            \"result\": \"\",\n",
        "            \"pods\": [],\n",
        "            \"raw\": data,\n",
        "        }\n",
        "\n",
        "    pods = query_result.get(\"pods\", []) or []\n",
        "    priority_titles = [\n",
        "        \"result\", \"results\", \"solution\", \"solutions\",\n",
        "        \"definite integral\", \"indefinite integral\",\n",
        "        \"derivative\", \"limit\", \"sum\", \"root\", \"roots\", \"exact result\",\n",
        "    ]\n",
        "\n",
        "    extracted_pods = []\n",
        "    primary_result = \"\"\n",
        "\n",
        "    for pod in pods:\n",
        "        title = pod.get(\"title\", \"\")\n",
        "        pod_text = _extract_pod_text(pod)\n",
        "\n",
        "        if not pod_text:\n",
        "            continue\n",
        "\n",
        "        extracted_pods.append({\"title\": title, \"text\": pod_text})\n",
        "\n",
        "        if not primary_result and title.lower() in priority_titles:\n",
        "            primary_result = pod_text\n",
        "\n",
        "    if not primary_result and extracted_pods:\n",
        "        primary_result = extracted_pods[0][\"text\"]\n",
        "\n",
        "    return {\n",
        "        \"ok\": True,\n",
        "        \"result\": primary_result,\n",
        "        \"pods\": extracted_pods,\n",
        "        \"raw\": data,\n",
        "    }\n",
        "\n",
        "\n",
        "def _extract_pod_text(pod: dict) -> str:\n",
        "    \"\"\"Extract plaintext content from a Wolfram|Alpha pod.\"\"\"\n",
        "    parts = []\n",
        "    for subpod in pod.get(\"subpods\", []) or []:\n",
        "        text = (subpod.get(\"plaintext\") or \"\").strip()\n",
        "        if text:\n",
        "            parts.append(text)\n",
        "    return \"\\n\".join(parts).strip()"
      ],
      "metadata": {
        "id": "SSphhCFuKFuP"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_steps_as_solution(step_results: list[dict], header: str = \"## Solution\") -> str:\n",
        "    \"\"\"Format executed step results into markdown solution text.\"\"\"\n",
        "    if not step_results:\n",
        "        return \"\"\n",
        "\n",
        "    parts = [header, \"\"]\n",
        "    for sr in step_results:\n",
        "        parts.append(f\"### Step {sr['step_number']}: {sr['description']}\\n\")\n",
        "        if sr.get(\"wolfram_result\"):\n",
        "            parts.append(f\"**Computation:**\\n```\\n{sr['wolfram_result']}\\n```\\n\")\n",
        "        reasoning = render_latex_for_markdown(sr['reasoning'])\n",
        "        parts.append(f\"{reasoning}\\n\")\n",
        "\n",
        "    return \"\\n\".join(parts)\n",
        "\n",
        "\n",
        "def format_plan_as_outline(plan: list[dict], header: str = \"## Solution Outline\") -> str:\n",
        "    \"\"\"Format solution plan as a fallback outline when steps weren't executed.\"\"\"\n",
        "    if not plan:\n",
        "        return \"_No solution plan available._\"\n",
        "\n",
        "    parts = [header, \"\", \"_Full solution could not be generated. Here is the planned approach:_\", \"\"]\n",
        "    for step in plan:\n",
        "        step_line = f\"**Step {step['step_number']} ({step['step_type']}):** {step['description']}\"\n",
        "        parts.append(step_line)\n",
        "        if step.get(\"wolfram_query\"):\n",
        "            parts.append(f\"  - Wolfram query: `{step['wolfram_query']}`\")\n",
        "        parts.append(\"\")\n",
        "\n",
        "    return \"\\n\".join(parts)"
      ],
      "metadata": {
        "id": "dxkTJh4cKFuP"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nodes"
      ],
      "metadata": {
        "id": "7R7T2DGVKFuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def quick_solve(state: SolverState) -> dict:\n",
        "    \"\"\"Solve directly using Wolfram|Alpha without step-by-step explanation.\"\"\"\n",
        "    problem = state[\"problem\"]\n",
        "    token_usage = dict(state.get(\"token_usage\", {\"input\": 0, \"output\": 0, \"total\": 0}))\n",
        "    usage_log = list(state.get(\"usage_log\", []))\n",
        "\n",
        "    wolfram_query = getattr(problem, \"wolfram_query\", None)\n",
        "\n",
        "    if not wolfram_query:\n",
        "        statement = problem.statement_latex\n",
        "        for prefix in [\"Compute:\", \"Solve:\", \"Evaluate:\", \"Find:\", \"Simplify:\", \"Calculate:\"]:\n",
        "            if statement.startswith(prefix):\n",
        "                statement = statement[len(prefix):].strip()\n",
        "                break\n",
        "        wolfram_query = statement.replace(\"$\", \"\").replace(\"\\\\,\", \" \").replace(\"\\\\\", \" \").strip()\n",
        "\n",
        "    wa_result = wolfram_solve(wolfram_query, WOLFRAM_APP_ID)\n",
        "    wa_calls = 1\n",
        "\n",
        "    if not wa_result.get(\"ok\") or not wa_result.get(\"result\"):\n",
        "        return {\n",
        "            \"solution\": \"\\n_Wolfram|Alpha could not solve this._\",\n",
        "            \"best_solution\": \"\\n_Wolfram|Alpha could not solve this._\",\n",
        "            \"solution_errors\": [\"Wolfram|Alpha failed\"],\n",
        "            \"best_solution_errors\": [\"Wolfram|Alpha failed\"],\n",
        "            \"solution_attempts\": 1,\n",
        "            \"wa_calls\": wa_calls,\n",
        "            \"token_usage\": token_usage,\n",
        "            \"usage_log\": usage_log,\n",
        "        }\n",
        "\n",
        "    conversion = wolfram_to_latex(\n",
        "        plaintext=wa_result[\"result\"],\n",
        "        token_usage=token_usage,\n",
        "        usage_log=usage_log,\n",
        "    )\n",
        "\n",
        "    latex_result = conversion[\"latex\"]\n",
        "    token_usage = conversion[\"token_usage\"]\n",
        "    usage_log = conversion[\"usage_log\"]\n",
        "\n",
        "    if latex_result:\n",
        "        solution = f\"\\n${latex_result}$\"\n",
        "    else:\n",
        "        solution = f\"\\n```\\n{wa_result['result']}\\n```\"\n",
        "\n",
        "    return {\n",
        "        \"solution\": solution,\n",
        "        \"best_solution\": solution,\n",
        "        \"solution_errors\": [],\n",
        "        \"best_solution_errors\": [],\n",
        "        \"solution_attempts\": 1,\n",
        "        \"wa_calls\": wa_calls,\n",
        "        \"token_usage\": token_usage,\n",
        "        \"usage_log\": usage_log,\n",
        "    }"
      ],
      "metadata": {
        "id": "b5CeNPKR5o4Z"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plan_solution(state: SolverState) -> dict:\n",
        "    \"\"\"Builds a step-by-step plan to solve the problem.\"\"\"\n",
        "    problem_text = state[\"problem\"].statement_latex\n",
        "\n",
        "    planning_prompt = SOLUTION_PLANNER_USER.format(problem_statement=problem_text, max_steps=MAX_PLAN_STEPS, max_tokens=MAX_STEP_SIZE_TOKENS)\n",
        "\n",
        "    result = robust_parse(\n",
        "        client=client,\n",
        "        instructions=SOLUTION_PLANNER_SYSTEM,\n",
        "        prompt=planning_prompt,\n",
        "        response_format=SolutionPlan,\n",
        "        temperature=0.4,\n",
        "        max_completion_tokens=1500,\n",
        "        max_retries=3,\n",
        "    )\n",
        "\n",
        "    plan: SolutionPlan = result[\"parsed\"]\n",
        "    steps = [s.model_dump() for s in plan.steps]\n",
        "\n",
        "    usage = result[\"usage\"]\n",
        "    token_usage = dict(state.get(\"token_usage\", {\"input\": 0, \"output\": 0, \"total\": 0}))\n",
        "    usage_log = list(state.get(\"usage_log\", []))\n",
        "\n",
        "    if usage is not None:\n",
        "        token_usage[\"input\"] += int(getattr(usage, \"input_tokens\", 0))\n",
        "        token_usage[\"output\"] += int(getattr(usage, \"output_tokens\", 0))\n",
        "        token_usage[\"total\"] += int(getattr(usage, \"total_tokens\", 0))\n",
        "        usage_log.append({\n",
        "            \"stage\": \"plan_solution\",\n",
        "            \"attempts\": result[\"attempts\"],\n",
        "            \"input_tokens\": int(getattr(usage, \"input_tokens\", 0)),\n",
        "            \"output_tokens\": int(getattr(usage, \"output_tokens\", 0)),\n",
        "            \"total_tokens\": int(getattr(usage, \"total_tokens\", 0)),\n",
        "        })\n",
        "\n",
        "    return {\n",
        "        \"solution_plan\": steps,\n",
        "        \"current_step_index\": 0,\n",
        "        \"step_results\": [],\n",
        "        \"wa_calls\": state.get(\"wa_calls\", 0),\n",
        "        \"token_usage\": token_usage,\n",
        "        \"usage_log\": usage_log,\n",
        "    }"
      ],
      "metadata": {
        "id": "K6u87CisKFuW"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def execute_step(state: SolverState) -> dict:\n",
        "    \"\"\"Executes a single step of the solution plan.\"\"\"\n",
        "    plan = state[\"solution_plan\"]\n",
        "    idx = state[\"current_step_index\"]\n",
        "\n",
        "    if idx >= len(plan):\n",
        "        return {\"current_step_index\": idx}\n",
        "\n",
        "    step = plan[idx]\n",
        "    problem_text = state[\"problem\"].statement_latex\n",
        "    step_results = list(state.get(\"step_results\", []))\n",
        "    wa_calls = state.get(\"wa_calls\", 0)\n",
        "    token_usage = dict(state.get(\"token_usage\", {\"input\": 0, \"output\": 0, \"total\": 0}))\n",
        "    usage_log = list(state.get(\"usage_log\", []))\n",
        "\n",
        "    wolfram_result = \"\"\n",
        "\n",
        "    try:\n",
        "        if step[\"step_type\"] == \"symbolic_compute\" and step.get(\"wolfram_query\"):\n",
        "            query = step[\"wolfram_query\"].strip()\n",
        "            if query and WOLFRAM_APP_ID:\n",
        "                try:\n",
        "                    wa_res = wolfram_solve(query, WOLFRAM_APP_ID)\n",
        "                    wa_calls += 1\n",
        "                    wolfram_result = wa_res.get(\"text\", \"\") if wa_res.get(\"ok\") else f\"_Wolfram could not compute: {query}_\"\n",
        "                except Exception as e:\n",
        "                    wolfram_result = f\"_Wolfram API error: {str(e)[:100]}_\"\n",
        "                    wa_calls += 1\n",
        "\n",
        "        if step_results:\n",
        "            prev_parts = [f\"**Step {sr['step_number']}:** {sr['description']}\\n{sr['reasoning'][:1000]}...\" for sr in step_results[-3:]]\n",
        "            previous_steps_text = \"\\n\\n\".join(prev_parts)\n",
        "        else:\n",
        "            previous_steps_text = \"_This is the first step._\"\n",
        "\n",
        "        prompt = STEP_EXECUTOR_USER.format(\n",
        "            problem_statement=problem_text,\n",
        "            step_number=step[\"step_number\"],\n",
        "            step_description=step[\"description\"],\n",
        "            previous_steps=previous_steps_text,\n",
        "            wolfram_result=wolfram_result if wolfram_result else \"_N/A - this is a reasoning step._\",\n",
        "        )\n",
        "\n",
        "        resp = client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            service_tier=SERVICE_TIER,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": STEP_EXECUTOR_SYSTEM},\n",
        "                {\"role\": \"user\", \"content\": prompt},\n",
        "            ],\n",
        "            temperature=0.5,\n",
        "            max_completion_tokens=1200,\n",
        "        )\n",
        "\n",
        "        reasoning = resp.choices[0].message.content\n",
        "\n",
        "        usage = getattr(resp, \"usage\", None)\n",
        "        if usage is not None:\n",
        "            token_usage[\"input\"] += int(getattr(usage, \"prompt_tokens\", 0))\n",
        "            token_usage[\"output\"] += int(getattr(usage, \"completion_tokens\", 0))\n",
        "            token_usage[\"total\"] += int(getattr(usage, \"total_tokens\", 0))\n",
        "            usage_log.append({\n",
        "                \"stage\": f\"execute_step_{step['step_number']}\",\n",
        "                \"input_tokens\": int(getattr(usage, \"prompt_tokens\", 0)),\n",
        "                \"output_tokens\": int(getattr(usage, \"completion_tokens\", 0)),\n",
        "                \"total_tokens\": int(getattr(usage, \"total_tokens\", 0)),\n",
        "            })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[execute_step] Error on step {step['step_number']}: {e}\")\n",
        "        reasoning = f\"_Step execution failed: {str(e)[:100]}_\"\n",
        "\n",
        "    step_results.append({\n",
        "        \"step_number\": step[\"step_number\"],\n",
        "        \"step_type\": step[\"step_type\"],\n",
        "        \"description\": step[\"description\"],\n",
        "        \"wolfram_query\": step.get(\"wolfram_query\", \"\"),\n",
        "        \"wolfram_result\": wolfram_result,\n",
        "        \"reasoning\": reasoning,\n",
        "    })\n",
        "\n",
        "    return {\n",
        "        \"step_results\": step_results,\n",
        "        \"current_step_index\": idx + 1,\n",
        "        \"wa_calls\": wa_calls,\n",
        "        \"token_usage\": token_usage,\n",
        "        \"usage_log\": usage_log,\n",
        "    }"
      ],
      "metadata": {
        "id": "j0X6QK-sKFuW"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compile_solution(state: SolverState) -> dict:\n",
        "    \"\"\"Builds a polished solution from the executed steps.\"\"\"\n",
        "    problem_text = state[\"problem\"].statement_latex\n",
        "    step_results = state.get(\"step_results\", [])\n",
        "    token_usage = dict(state.get(\"token_usage\", {\"input\": 0, \"output\": 0, \"total\": 0}))\n",
        "    usage_log = list(state.get(\"usage_log\", []))\n",
        "\n",
        "    if not step_results:\n",
        "        return {\n",
        "            \"solution\": format_plan_as_outline(state.get(\"solution_plan\", [])),\n",
        "            \"token_usage\": token_usage,\n",
        "            \"usage_log\": usage_log,\n",
        "        }\n",
        "\n",
        "    all_steps_text = []\n",
        "    for sr in step_results:\n",
        "        step_text = f\"### Step {sr['step_number']}: {sr['description']}\\n\\n\"\n",
        "        if sr.get(\"wolfram_result\"):\n",
        "            step_text += f\"**Wolfram|Alpha computation:**\\n{sr['wolfram_result']}\\n\\n\"\n",
        "        step_text += f\"**Reasoning:**\\n{sr['reasoning']}\"\n",
        "        all_steps_text.append(step_text)\n",
        "\n",
        "    prompt = SOLUTION_COMPILER_USER.format(\n",
        "        problem_statement=problem_text,\n",
        "        all_steps=\"\\n\\n---\\n\\n\".join(all_steps_text),\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        resp = client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            service_tier=SERVICE_TIER,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": SOLUTION_COMPILER_SYSTEM},\n",
        "                {\"role\": \"user\", \"content\": prompt},\n",
        "            ],\n",
        "            temperature=0.5,\n",
        "            max_completion_tokens=2500,\n",
        "        )\n",
        "\n",
        "        solution = resp.choices[0].message.content\n",
        "\n",
        "        usage = getattr(resp, \"usage\", None)\n",
        "        if usage is not None:\n",
        "            token_usage[\"input\"] += int(getattr(usage, \"prompt_tokens\", 0))\n",
        "            token_usage[\"output\"] += int(getattr(usage, \"completion_tokens\", 0))\n",
        "            token_usage[\"total\"] += int(getattr(usage, \"total_tokens\", 0))\n",
        "            usage_log.append({\n",
        "                \"stage\": \"compile_solution\",\n",
        "                \"input_tokens\": int(getattr(usage, \"prompt_tokens\", 0)),\n",
        "                \"output_tokens\": int(getattr(usage, \"completion_tokens\", 0)),\n",
        "                \"total_tokens\": int(getattr(usage, \"total_tokens\", 0)),\n",
        "            })\n",
        "\n",
        "        return {\"solution\": solution, \"token_usage\": token_usage, \"usage_log\": usage_log}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[compile_solution] Error: {e}\")\n",
        "        return {\n",
        "            \"solution\": format_steps_as_solution(step_results, \"## Solution (Raw Steps)\"),\n",
        "            \"token_usage\": token_usage,\n",
        "            \"usage_log\": usage_log,\n",
        "        }"
      ],
      "metadata": {
        "id": "3s0J-J7GKFuW"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_solution(state: SolverState) -> dict:\n",
        "    \"\"\"Validates the solution and tracks the best one.\"\"\"\n",
        "    solution = state.get(\"solution\", \"\")\n",
        "    errors = []\n",
        "\n",
        "    if len(solution) < 200:\n",
        "        errors.append(\"Solution is too short.\")\n",
        "\n",
        "    if \"$\" not in solution:\n",
        "        errors.append(\"Solution lacks mathematical notation.\")\n",
        "\n",
        "    plan = state.get(\"solution_plan\", [])\n",
        "    results = state.get(\"step_results\", [])\n",
        "    if len(results) < len(plan):\n",
        "        errors.append(f\"Only {len(results)}/{len(plan)} steps were executed.\")\n",
        "\n",
        "    math_keywords = [\"integral\", \"derivative\", \"=\", \"therefore\", \"thus\", \"hence\", \"solve\", \"compute\"]\n",
        "    has_math_content = any(kw in solution.lower() for kw in math_keywords)\n",
        "    if not has_math_content:\n",
        "        errors.append(\"Solution may lack mathematical reasoning.\")\n",
        "\n",
        "    # Track best solution\n",
        "    current_solution = solution\n",
        "    current_step_results = state.get(\"step_results\", [])\n",
        "    best_solution = state.get(\"best_solution\", \"\")\n",
        "    best_errors = state.get(\"best_solution_errors\", None)\n",
        "    best_step_results = state.get(\"best_solution_step_results\", [])\n",
        "\n",
        "    is_better = (\n",
        "        best_errors is None or\n",
        "        len(errors) < len(best_errors) or\n",
        "        (len(errors) == len(best_errors) and len(current_solution) > len(best_solution))\n",
        "    )\n",
        "\n",
        "    if is_better and current_solution:\n",
        "        best_solution = current_solution\n",
        "        best_errors = errors\n",
        "        best_step_results = current_step_results\n",
        "\n",
        "    return {\n",
        "        \"solution_errors\": errors,\n",
        "        \"solution_attempts\": state.get(\"solution_attempts\", 0) + 1,\n",
        "        \"best_solution\": best_solution,\n",
        "        \"best_solution_errors\": best_errors if best_errors is not None else errors,\n",
        "        \"best_solution_step_results\": best_step_results,\n",
        "    }"
      ],
      "metadata": {
        "id": "d5PR7An_KFuW"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def finalize_solution(state: SolverState) -> dict:\n",
        "    \"\"\"Finalizes the output: renders markdown and translates if needed.\"\"\"\n",
        "    solution = state.get(\"best_solution\") or state.get(\"solution\", \"\")\n",
        "    solution_errors = state.get(\"best_solution_errors\", [])\n",
        "\n",
        "    if not solution:\n",
        "        step_results = state.get(\"best_solution_step_results\") or state.get(\"step_results\", [])\n",
        "        if step_results:\n",
        "            solution = format_steps_as_solution(step_results)\n",
        "        else:\n",
        "            solution = format_plan_as_outline(state.get(\"solution_plan\", []))\n",
        "\n",
        "    if solution_errors:\n",
        "        disclaimer = (\n",
        "            \"\\n\\n---\\n\\n\"\n",
        "            \"> **Note:** This solution may contain errors or incomplete reasoning. \"\n",
        "            \"The following issues were detected:\\n\"\n",
        "        )\n",
        "        for err in solution_errors:\n",
        "            disclaimer += f\"> - {err}\\n\"\n",
        "        disclaimer += \">\\n> Please verify the steps independently.\"\n",
        "        solution += disclaimer\n",
        "\n",
        "    solution_md = render_latex_for_markdown(solution)\n",
        "\n",
        "    # Translate if target language specified\n",
        "    target_language = state.get(\"target_language\", \"\")\n",
        "    result = translate_text(\n",
        "        content=solution_md,\n",
        "        target_language=target_language,\n",
        "        token_usage=state.get(\"token_usage\"),\n",
        "        usage_log=state.get(\"usage_log\"),\n",
        "    )\n",
        "\n",
        "    tu = result[\"token_usage\"]\n",
        "    plan_len = len(state.get(\"solution_plan\", []))\n",
        "    executed = len(state.get(\"best_solution_step_results\") or state.get(\"step_results\", []))\n",
        "\n",
        "    summary = (\n",
        "        f\"Solution attempts: {state.get('solution_attempts', 0)} | \"\n",
        "        f\"Steps: {executed}/{plan_len} | \"\n",
        "        f\"WA calls: {state.get('wa_calls', 0)} | \"\n",
        "        f\"Errors: {len(solution_errors)} | \"\n",
        "        f\"Input Tokens: {tu.get('input', 0)} \"\n",
        "        f\"Output Tokens: {tu.get('output', 0)} \"\n",
        "        f\"Total Tokens: {tu.get('total', 0)}\"\n",
        "    )\n",
        "\n",
        "    if target_language:\n",
        "        summary += f\" | Language: {target_language}\"\n",
        "\n",
        "    return {\n",
        "        \"solution_markdown\": solution_md,\n",
        "        \"solution_markdown_translated\": result[\"translated\"],\n",
        "        \"token_usage\": result[\"token_usage\"],\n",
        "        \"usage_log\": result[\"usage_log\"],\n",
        "        \"summary\": summary,\n",
        "    }"
      ],
      "metadata": {
        "id": "CkAOw4VMKFuW"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Edges"
      ],
      "metadata": {
        "id": "0W7WL4F-KFuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def route_solver_mode(state: SolverState) -> str:\n",
        "    \"\"\"Route based on step_by_step flag.\"\"\"\n",
        "    if state.get(\"step_by_step\", True):\n",
        "        return \"step_by_step\"\n",
        "    return \"quick\"\n",
        "\n",
        "def route_step_execution(state: SolverState) -> str:\n",
        "    \"\"\"Loop controller. Checks if there are more steps to execute.\"\"\"\n",
        "    plan = state[\"solution_plan\"]\n",
        "    idx = state[\"current_step_index\"]\n",
        "    return \"continue\" if idx < len(plan) else \"compile\"\n",
        "\n",
        "\n",
        "def route_after_solution_validate(state: SolverState) -> str:\n",
        "    \"\"\"Routes based on solution validation. Retries if errors found.\"\"\"\n",
        "    errors = state.get(\"solution_errors\", [])\n",
        "    attempts = state.get(\"solution_attempts\", 0)\n",
        "\n",
        "    if not errors:\n",
        "        return \"done\"\n",
        "    if attempts < 3:\n",
        "        return \"retry\"\n",
        "    return \"done\""
      ],
      "metadata": {
        "id": "xAtIGFg6KFuW"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compilation"
      ],
      "metadata": {
        "id": "n-ziW9i5KFuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "solver_graph = StateGraph(SolverState)\n",
        "\n",
        "solver_graph.add_node(\"quick_solve\", quick_solve)\n",
        "solver_graph.add_node(\"plan_solution\", plan_solution)\n",
        "solver_graph.add_node(\"execute_step\", execute_step)\n",
        "solver_graph.add_node(\"compile_solution\", compile_solution)\n",
        "solver_graph.add_node(\"validate_solution\", validate_solution)\n",
        "solver_graph.add_node(\"finalize_solution\", finalize_solution)\n",
        "\n",
        "solver_graph.add_conditional_edges(\n",
        "    START,\n",
        "    route_solver_mode,\n",
        "    {\"step_by_step\": \"plan_solution\", \"quick\": \"quick_solve\"},\n",
        ")\n",
        "\n",
        "# Quick solve path\n",
        "solver_graph.add_edge(\"quick_solve\", \"finalize_solution\")\n",
        "\n",
        "# Step-by-step path\n",
        "solver_graph.add_edge(\"plan_solution\", \"execute_step\")\n",
        "\n",
        "solver_graph.add_conditional_edges(\n",
        "    \"execute_step\",\n",
        "    route_step_execution,\n",
        "    {\"continue\": \"execute_step\", \"compile\": \"compile_solution\"},\n",
        ")\n",
        "\n",
        "solver_graph.add_edge(\"compile_solution\", \"validate_solution\")\n",
        "\n",
        "solver_graph.add_conditional_edges(\n",
        "    \"validate_solution\",\n",
        "    route_after_solution_validate,\n",
        "    {\"retry\": \"plan_solution\", \"done\": \"finalize_solution\"},\n",
        ")\n",
        "\n",
        "solver_graph.add_edge(\"finalize_solution\", END)\n",
        "\n",
        "problem_solver = solver_graph.compile()"
      ],
      "metadata": {
        "id": "Q3k13lIyKFuX"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Invocation"
      ],
      "metadata": {
        "id": "iFZDZaYJKFuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# CONFIGURATION\n",
        "# =====================================================\n",
        "\n",
        "# Mode: \"equation\" or \"problem\"\n",
        "MODE = \"problem\"  # @param [\"equation\", \"problem\"]\n",
        "\n",
        "# Solver mode: step-by-step explanation or quick WA answer\n",
        "QUICK_SOLUTION = False  # @param {type:\"boolean\"}\n",
        "QUICK_SOLUTION = QUICK_SOLUTION and MODE == 'equation' # allow quick solutions for Equations only\n",
        "\n",
        "# Problem/Equation parameters\n",
        "DOMAIN = \"calculus\" # @param [\"calculus\",\"linear_algebra\",\"algebra\"]\n",
        "TOPIC = \"Volume Calculation\"  # @param {type:\"string\"}\n",
        "DIFFICULTY = \"medium\"  # @param [\"easy\", \"medium\", \"hard\"]\n",
        "\n",
        "# Language for output (empty or \"English\" = no translation)\n",
        "LANGUAGE = \"Ukrainian\"  # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "1oqQanE36Dc8"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# GENERATE\n",
        "# =====================================================\n",
        "\n",
        "%%time\n",
        "if MODE == \"equation\":\n",
        "    gen_result = equation_generator.invoke({\n",
        "        \"domain\": DOMAIN,\n",
        "        \"topic\": TOPIC,\n",
        "        \"difficulty\": DIFFICULTY,\n",
        "        \"target_language\": LANGUAGE,\n",
        "    })\n",
        "\n",
        "    # Extract for solver\n",
        "    item = gen_result[\"equation\"]\n",
        "    item_markdown = gen_result[\"equation_markdown\"]\n",
        "    item_translated = gen_result[\"equation_markdown_translated\"]\n",
        "\n",
        "    print(\"=== EQUATION ===\")\n",
        "    display(Markdown(item_markdown))\n",
        "    if LANGUAGE and LANGUAGE.lower() != \"english\":\n",
        "        print(f\"\\n=== EQUATION ({LANGUAGE}) ===\")\n",
        "        display(Markdown(item_translated))\n",
        "\n",
        "else:  # problem\n",
        "    gen_result = problem_generator.invoke({\n",
        "        \"domain\": DOMAIN,\n",
        "        \"topic\": TOPIC,\n",
        "        \"difficulty\": DIFFICULTY,\n",
        "        \"target_language\": LANGUAGE,\n",
        "    })\n",
        "\n",
        "    # Extract for solver\n",
        "    item = gen_result[\"problem\"]\n",
        "    item_markdown = gen_result[\"problem_markdown\"]\n",
        "    item_translated = gen_result[\"problem_markdown_translated\"]\n",
        "\n",
        "    print(\"=== PROBLEM ===\")\n",
        "    display(Markdown(item_markdown))\n",
        "    if LANGUAGE and LANGUAGE.lower() != \"english\":\n",
        "        print(f\"\\n=== PROBLEM ({LANGUAGE}) ===\")\n",
        "        display(Markdown(item_translated))\n",
        "\n",
        "# Print token usage\n",
        "tu = gen_result.get(\"token_usage\", {})\n",
        "print(f\"\\n📊 Generation Tokens: {format_token_summary(tu)}\")\n",
        "print(f\"Errors: {gen_result.get('errors', [])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "m_LTHwuBxGCH",
        "outputId": "4182582f-ff9b-4bf6-948e-a205022a0263"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== PROBLEM ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Construct a function $f:[0,1]\\to\\mathbb{R}$ from the quadratic family\n$$f(x)=ax^2+bx+c$$\nthat satisfies the endpoint constraints $f(0)=1$ and $f(1)=2$, and has the additional constraint that its slope at the left endpoint is zero: $f'(0)=0$.\n\nWhen the graph of $y=f(x)$ on $[0,1]$ is revolved about the $x$-axis, it generates a solid with volume\n$$V=\\pi\\int_0^1 \\big(f(x)\\big)^2\\,dx.$$\n\nDetermine the coefficients $a,b,c$ so that the resulting solid has prescribed volume\n$$V=\\frac{31\\pi}{5}.$$\n\n(Your constructed $f$ should satisfy all three constraints and the volume condition.)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== PROBLEM (Ukrainian) ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Побудуйте функцію $f:[0,1]\\to\\mathbb{R}$ із квадратичної родини\n$$f(x)=ax^2+bx+c$$\nяка задовольняє крайові умови $f(0)=1$ та $f(1)=2$, а також додаткову умову, що її похідна в лівій крайовій точці дорівнює нулю: $f'(0)=0$.\n\nКоли графік $y=f(x)$ на $[0,1]$ обертається навколо осі $x$, він утворює тіло з об’ємом\n$$V=\\pi\\int_0^1 \\big(f(x)\\big)^2\\,dx.$$\n\nВизначте коефіцієнти $a,b,c$ так, щоб отримане тіло мало заданий об’єм\n$$V=\\frac{31\\pi}{5}.$$\n\n(Побудована вами функція $f$ має задовольняти всі три умови та умову на об’єм.)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Generation Tokens: Input: 925 | Output: 972 | Total: 1897\n",
            "Errors: []\n",
            "CPU times: user 484 ms, sys: 41.9 ms, total: 526 ms\n",
            "Wall time: 14 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solve the Problem"
      ],
      "metadata": {
        "id": "JlTQPNceKFuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# SOLVE\n",
        "# =====================================================\n",
        "\n",
        "%%time\n",
        "solve_result = problem_solver.invoke({\n",
        "    \"problem\": item,\n",
        "    \"target_language\": LANGUAGE,\n",
        "    \"step_by_step\": not QUICK_SOLUTION,\n",
        "}, {\"recursion_limit\": 50})\n",
        "\n",
        "# Print plan only if step-by-step\n",
        "if not QUICK_SOLUTION:\n",
        "    print(\"=== SOLUTION PLAN ===\")\n",
        "    for step in solve_result.get(\"solution_plan\", []):\n",
        "        step_desc = step['description'][:80] + \"...\" if len(step['description']) > 80 else step['description']\n",
        "        print(f\"  Step {step['step_number']} [{step['step_type']}]: {step_desc}\")\n",
        "        if step.get(\"wolfram_query\"):\n",
        "            print(f\"    → WA: {step['wolfram_query']}\")\n",
        "    print()\n",
        "\n",
        "# Print summary\n",
        "tu = solve_result.get(\"token_usage\", {})\n",
        "print(f\"📊 Solution Tokens: {format_token_summary(tu)}\")\n",
        "print(f\"WA calls: {solve_result.get('wa_calls', 0)} | Errors: {len(solve_result.get('solution_errors', []))}\")\n",
        "if solve_result.get(\"solution_errors\"):\n",
        "    print(f\"Solution errors: {solve_result['solution_errors']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az8neKsJKFuX",
        "outputId": "c3987a23-1980-4dd2-b35b-cef1b17d48a1"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== SOLUTION PLAN ===\n",
            "  Step 1 [reasoning]: Write f(x)=ax^2+bx+c and translate endpoint/slope constraints into equations: f(...\n",
            "  Step 2 [symbolic_compute]: Compute f'(x) and apply f'(0)=0 to get an equation in a,b.\n",
            "    → WA: Differentiate a x^2 + b x + c with respect to x\n",
            "  Step 3 [reasoning]: Apply f(0)=1 to solve for c.\n",
            "  Step 4 [symbolic_compute]: Apply f(1)=2 and the slope condition equation to solve for a and b (with c alrea...\n",
            "    → WA: Solve[{a*1^2 + b*1 + 1 == 2, b == 0},{a,b}]\n",
            "  Step 5 [reasoning]: Substitute a,b,c into f(x) to get the explicit quadratic.\n",
            "  Step 6 [symbolic_compute]: Set up the volume condition V=pi*Integrate[(f(x))^2,{x,0,1}] and compute the int...\n",
            "    → WA: Integrate[(a x^2 + b x + c)^2,{x,0,1}]\n",
            "  Step 7 [symbolic_compute]: Impose the prescribed volume by setting the computed integral equal to 31/5 and ...\n",
            "    → WA: Solve[Integrate[(a x^2 + b x + c)^2,{x,0,1}] == 31/5 && c==1 && b==0 && a==1, {a,b,c}]\n",
            "  Step 8 [verify]: Verify: check f(0)=1, f(1)=2, f'(0)=0, and V=31 pi/5 with the final coefficients...\n",
            "\n",
            "📊 Solution Tokens: Input: 33514 | Output: 11499 | Total: 45013\n",
            "WA calls: 11 | Errors: 1\n",
            "Solution errors: ['Solution lacks mathematical notation.']\n",
            "CPU times: user 270 ms, sys: 39.2 ms, total: 309 ms\n",
            "Wall time: 2min 25s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# DISPLAY SOLUTION\n",
        "# =====================================================\n",
        "\n",
        "print(\"=== SOLUTION ===\")\n",
        "print_solution(solve_result[\"solution_markdown\"])\n",
        "\n",
        "if LANGUAGE and LANGUAGE.lower() != \"english\":\n",
        "    print(f\"\\n=== SOLUTION ({LANGUAGE}) ===\")\n",
        "    print_solution(solve_result[\"solution_markdown_translated\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JUUMnM_d67oB",
        "outputId": "76d0ddb9-b2fd-414c-865b-16cddd9e4766"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== SOLUTION ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Solution\n\nLet\n$$\nf(x)=ax^2+bx+c,\\qquad x\\in[0,1].\n$$\n\n### 1) Impose the endpoint constraints $f(0)=1$ and $f(1)=2$\n\nFrom $f(0)=1$:\n$$\nf(0)=c=1 \\quad\\Longrightarrow\\quad c=1.\n$$\n\nFrom $f(1)=2$:\n$$\nf(1)=a+b+c=2.\n$$\nSubstitute $c=1$:\n$$\na+b+1=2 \\quad\\Longrightarrow\\quad a+b=1.\n$$\n\nSo far,\n$$\nc=1,\\qquad a+b=1.\n$$\n\n### 2) Impose the slope constraint $f'(0)=0$\n\nDifferentiate:\n$$\nf'(x)=2ax+b.\n$$\nThen\n$$\nf'(0)=b=0 \\quad\\Longrightarrow\\quad b=0.\n$$\n\nSubstitute $b=0$ into $a+b=1$:\n$$\na=1.\n$$\n\nThus the three constraints $f(0)=1$, $f(1)=2$, $f'(0)=0$ force a *unique* quadratic:\n$$\n(a,b,c)=(1,0,1),\\qquad f(x)=x^2+1.\n$$\n\n### 3) Compute the resulting volume and compare with the prescribed value\n\nThe volume of the solid of revolution about the $x$-axis is\n$$\nV=\\pi\\int_0^1 (f(x))^2\\,dx=\\pi\\int_0^1 (x^2+1)^2\\,dx.\n$$\nExpand:\n$$\n(x^2+1)^2=x^4+2x^2+1.\n$$\nIntegrate term-by-term:\n$$\n\\int_0^1 (x^4+2x^2+1)\\,dx\n=\\left[\\frac{x^5}{5}\\right]_0^1+2\\left[\\frac{x^3}{3}\\right]_0^1+\\left[x\\right]_0^1\n=\\frac15+\\frac23+1=\\frac{28}{15}.\n$$\nHence\n$$\nV=\\pi\\cdot\\frac{28}{15}=\\frac{28\\pi}{15}.\n$$\n\nBut the prescribed volume is\n$$\n\\frac{31\\pi}{5}.\n$$\nSince\n$$\n\\frac{28\\pi}{15}\\neq \\frac{31\\pi}{5},\n$$\nthe volume condition is incompatible with the three point/slope constraints.\n\n---\n\n## Final Answer\n\nThe constraints $f(0)=1$, $f(1)=2$, and $f'(0)=0$ uniquely determine\n$$\n\\boxed{(a,b,c)=(1,0,1)} \\quad\\text{so}\\quad \\boxed{f(x)=x^2+1}.\n$$\nThis function generates volume\n$$\n\\boxed{V=\\frac{28\\pi}{15}},\n$$\nso **no quadratic** $ax^2+bx+c$ can satisfy *all* three constraints **and** the prescribed volume $V=\\dfrac{31\\pi}{5}$ simultaneously.\n\n---\n\n> **Note:** This solution may contain errors or incomplete reasoning. The following issues were detected:\n> - Solution lacks mathematical notation.\n>\n> Please verify the steps independently."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== SOLUTION (Ukrainian) ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Розв’язання\n\nНехай\n$$\nf(x)=ax^2+bx+c,\\qquad x\\in[0,1].\n$$\n\n### 1) Накладімо крайові умови $f(0)=1$ і $f(1)=2$\n\nІз $f(0)=1$:\n$$\nf(0)=c=1 \\quad\\Longrightarrow\\quad c=1.\n$$\n\nІз $f(1)=2$:\n$$\nf(1)=a+b+c=2.\n$$\nПідставимо $c=1$:\n$$\na+b+1=2 \\quad\\Longrightarrow\\quad a+b=1.\n$$\n\nОтже, наразі\n$$\nc=1,\\qquad a+b=1.\n$$\n\n### 2) Накладімо умову на похідну $f'(0)=0$\n\nПродиференціюймо:\n$$\nf'(x)=2ax+b.\n$$\nТоді\n$$\nf'(0)=b=0 \\quad\\Longrightarrow\\quad b=0.\n$$\n\nПідставимо $b=0$ у $a+b=1$:\n$$\na=1.\n$$\n\nОтже, три умови $f(0)=1$, $f(1)=2$, $f'(0)=0$ задають *єдиний* квадратний многочлен:\n$$\n(a,b,c)=(1,0,1),\\qquad f(x)=x^2+1.\n$$\n\n### 3) Обчислімо отриманий об’єм і порівняймо із заданим значенням\n\nОб’єм тіла обертання навколо осі $x$ дорівнює\n$$\nV=\\pi\\int_0^1 (f(x))^2\\,dx=\\pi\\int_0^1 (x^2+1)^2\\,dx.\n$$\nРозкриємо дужки:\n$$\n(x^2+1)^2=x^4+2x^2+1.\n$$\nПроінтегруймо почленно:\n$$\n\\int_0^1 (x^4+2x^2+1)\\,dx\n=\\left[\\frac{x^5}{5}\\right]_0^1+2\\left[\\frac{x^3}{3}\\right]_0^1+\\left[x\\right]_0^1\n=\\frac15+\\frac23+1=\\frac{28}{15}.\n$$\nОтже,\n$$\nV=\\pi\\cdot\\frac{28}{15}=\\frac{28\\pi}{15}.\n$$\n\nАле заданий об’єм дорівнює\n$$\n\\frac{31\\pi}{5}.\n$$\nОскільки\n$$\n\\frac{28\\pi}{15}\\neq \\frac{31\\pi}{5},\n$$\nумова на об’єм несумісна з трьома умовами на значення/нахил у точках.\n\n---\n\n## Остаточна відповідь\n\nУмови $f(0)=1$, $f(1)=2$ та $f'(0)=0$ однозначно визначають\n$$\n\\boxed{(a,b,c)=(1,0,1)} \\quad\\text{тобто}\\quad \\boxed{f(x)=x^2+1}.\n$$\nЦя функція породжує об’єм\n$$\n\\boxed{V=\\frac{28\\pi}{15}},\n$$\nтому **жоден квадратний многочлен** $ax^2+bx+c$ не може одночасно задовольняти *всі* три умови **та** заданий об’єм $V=\\dfrac{31\\pi}{5}$.\n\n---\n\n> **Примітка:** Це розв’язання може містити помилки або неповні міркування. Було виявлено такі проблеми:\n> - Розв’язання не містить математичних позначень.\n>\n> Будь ласка, перевірте кроки самостійно."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# COMBINED SUMMARY\n",
        "# =====================================================\n",
        "\n",
        "gen_tokens = gen_result.get(\"token_usage\", {})\n",
        "solve_tokens = solve_result.get(\"token_usage\", {})\n",
        "\n",
        "total_tokens = {\n",
        "    \"input\": gen_tokens.get(\"input\", 0) + solve_tokens.get(\"input\", 0),\n",
        "    \"output\": gen_tokens.get(\"output\", 0) + solve_tokens.get(\"output\", 0),\n",
        "    \"total\": gen_tokens.get(\"total\", 0) + solve_tokens.get(\"total\", 0),\n",
        "}\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"SUMMARY\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Mode: {MODE} | Step-by-step: {not QUICK_SOLUTION}\")\n",
        "print(f\"Domain: {DOMAIN} | Topic: {TOPIC} | Difficulty: {DIFFICULTY}\")\n",
        "print(f\"Language: {LANGUAGE or 'English'}\")\n",
        "print()\n",
        "print(f\"Generation Tokens: {format_token_summary(gen_tokens)}\")\n",
        "print(f\"Solution Tokens:   {format_token_summary(solve_tokens)}\")\n",
        "print(f\"TOTAL Tokens:      {format_token_summary(total_tokens)}\")\n",
        "print(f\"WA Calls: {solve_result.get('wa_calls', 0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5v3OIQoA68_H",
        "outputId": "002566d1-20bb-437d-e1c5-dc81e9eec411"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "SUMMARY\n",
            "==================================================\n",
            "Mode: problem | Step-by-step: True\n",
            "Domain: calculus | Topic: Volume Calculation | Difficulty: medium\n",
            "Language: Ukrainian\n",
            "\n",
            "Generation Tokens: Input: 925 | Output: 972 | Total: 1897\n",
            "Solution Tokens:   Input: 33514 | Output: 11499 | Total: 45013\n",
            "TOTAL Tokens:      Input: 34439 | Output: 12471 | Total: 46910\n",
            "WA Calls: 11\n"
          ]
        }
      ]
    }
  ]
}